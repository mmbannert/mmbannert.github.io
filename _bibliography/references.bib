% 
% This file was created by the Typo3 extension
% sevenpack version 0.7.14
% 
% --- Timezone: CEST
% Creation date: 2018-04-03
% Creation time: 22-10-11
% --- Number of references
% 12
% 

@Article { BannertB2018,
   title = {Human V4 Activity Patterns Predict Behavioral Performance in Imagery of Object Color},
   journal = {Journal of Neuroscience},
   year = {2018},
   month = {3},
   volume = {Epub ahead},
   abstract = {Color is special among basic visual features in that it can form a defining part of objects that are engrained in our memory. Whereas most neuroimaging research on human color vision has focused on responses related to external stimulation, the present study investigated how sensory-driven color vision is linked to subjective color perception induced by object imagery. We recorded fMRI activity in male and female volunteers during viewing of abstract color stimuli that were red, green, or yellow in half of the runs. In the other half we asked them to produce mental images of colored, meaningful objects (such as tomato, grapes, banana) corresponding to the same three color categories. Although physically presented color could be decoded from all retinotopically mapped visual areas, only hV4 allowed predicting colors of imagined objects when classifiers were trained on responses to physical colors. Importantly, only neural signal in hV4 was predictive of behavioral performance in the color judgment task on a trial-by-trial basis. The commonality between neural representations of sensory-driven and imagined object color and the behavioral link to neural representations in hV4 identifies area hV4 as a perceptual hub linking externally triggered color vision with color in self-generated object imagery.},
   department = {Department Logothetis},
   web_url = {http://www.jneurosci.org/content/early/2018/03/08/JNEUROSCI.2307-17.2018.full.pdf},
   DOI = {10.1523/JNEUROSCI.2307-17.2018},
   author = {Bannert, MM and Bartels, A}
}

@Article { BannertB2017,
   title = {Invariance of surface color representations across illuminant changes in the human cortex},
   journal = {NeuroImage},
   year = {2017},
   month = {9},
   volume = {158},
   pages = {356-370},
   abstract = {A central problem in color vision is that the light reaching the eye from a given surface can vary dramatically depending on the illumination. Despite this, our color percept, the brain's estimate of surface reflectance, remains remarkably stable. This phenomenon is called color constancy. Here we investigated which human brain regions represent surface color in a way that is invariant with respect to illuminant changes. We used physically realistic rendering methods to display natural yet abstract 3D scenes that were displayed under three distinct illuminants. The scenes embedded, in different conditions, surfaces that differed in their surface color (i.e. in their reflectance property). We used multivariate fMRI pattern analysis to probe neural coding of surface reflectance and illuminant, respectively. While all visual regions encoded surface color when viewed under the same illuminant, we found that only in V1 and V4\(\alpha\) surface color representations were invariant to illumination changes. Along the visual hierarchy there was a gradient from V1 to V4\(\alpha\) to increasingly encode surface color rather than illumination. Finally, effects of a stimulus manipulation on individual behavioral color constancy indices correlated with neural encoding of the illuminant in hV4. This provides neural evidence for the Equivalent Illuminant Model. Our results provide a principled characterization of color constancy mechanisms across the visual hierarchy, and demonstrate complementary contributions in early and late processing stages.},
   department = {Department Logothetis},
   web_url = {http://www.sciencedirect.com/science/article/pii/S105381191730561X?via\%3Dihub},
   DOI = {10.1016/j.neuroimage.2017.06.079},
   author = {Bannert, MM and Bartels, A}
}

@Article { BannertB2013,
   title = {Decoding the Yellow of a Gray Banana},
   journal = {Current Biology},
   year = {2013},
   month = {11},
   volume = {23},
   number = {22},
   pages = {2268&ndash;2272},
   abstract = {Some everyday objects are associated with a particular color, such as bananas, which are typically yellow. Behavioral studies show that perception of these so-called color-diagnostic objects is influenced by our knowledge of their typical color, referred to as memory color [1,2]. However, neural representations of memory colors are unknown. Here we investigated whether memory color can be decoded from visual cortex activity when color-diagnostic objects are viewed as grayscale images. We trained linear classifiers to distinguish patterns of fMRI responses to four different hues. We found that activity in V1 allowed predicting the memory color of color-diagnostic objects presented in grayscale in naive participants performing a motion task. The results imply that higher areas feed back memory-color signals to V1. When classifiers were trained on neural responses to some exemplars of color-diagnostic objects and tested on others, areas V4 and LOC also predicted memory colors. Representational similarity analysis showed that memory-color representations in V1 were correlated specifically with patterns in V4 but not LOC. Our findings suggest that prior knowledge is projected from midlevel visual regions onto primary visual cortex, consistent with predictive coding theory [3].},
   department = {Department Logothetis},
   web_url = {http://www.sciencedirect.com/science/article/pii/S0960982213011329},
   DOI = {10.1016/j.cub.2013.09.016},
   author = {Bannert, MM and Bartels, A}
}

@Article { FiehlerBBBSVFR2011,
   title = {Working memory maintenance of grasp-target information in the human posterior parietal cortex},
   journal = {NeuroImage},
   year = {2011},
   month = {2},
   volume = {54},
   number = {3},
   pages = {2401-2411},
   abstract = {Event-related functional magnetic resonance imaging was applied to identify cortical areas involved in maintaining target information in working memory used for an upcoming grasping action. Participants had to grasp with their thumb and index finger of the dominant right hand three-dimensional objects of different size and orientation. Reaching-to-grasp movements were performed without visual feedback either immediately after object presentation or after a variable delay of 2&ndash;12 s. The right inferior parietal cortex demonstrated sustained neural activity throughout the delay, which overlapped with activity observed during encoding of the grasp target. Immediate and delayed grasping activated similar motor-related brain areas and showed no differential activity. The results suggest that the right inferior parietal cortex plays an important functional role in working memory maintenance of grasp-related information. Moreover, our findings confirm the assumption that brain areas engaged in maintaining information are also involved in encoding the same information, and thus extend previous findings on working memory function of the posterior parietal cortex in saccadic behavior to reach-to-grasp movements.},
   department = {Department Logothetis},
   web_url = {http://www.sciencedirect.com/science?_ob=MImg\&_imagekey=B6WNP-515SRFP-7-F\&_cdi=6968\&_user=29041\&_pii=S1053811910012826\&_origin=\&_coverDate=02\%2F01\%2F2011\&_sk=999459996\&view=c\&wchp=dGLzVzb-zSkWW\&md5=ce2995ae61d933302149ce570e9287a3\&ie=/sdarticle.pdf},
   DOI = {10.1016/j.neuroimage.2010.09.080},
   author = {Fiehler, K and Bannert, MM and Bischoff, M and Blecker, C and Stark, R and Vaitl, D and Franz, VH and R{\"o}sler, F}
}

@Poster { BannertB2016,
   title = {The invariance of surface color representations across
illuminant changes in the human cortex},
   journal = {Journal of Vision},
   year = {2016},
   month = {9},
   volume = {16},
   number = {12},
   pages = {1155},
   abstract = {Color is the brain&rsquo;s estimate of reflectance for a given surface. Reflectance describes how much light a surface reflects at different wavelengths. Since the light reflected from a surface depends on its reflectance and on the spectral power distribution of the incident light, it is impossible to predict surface reflectance directly from the wavelength composition of the reflected light. Despite this computational problem, the human visual system is remarkably accurate at inferring the reflectance &ndash; perceived
as color &ndash; of surfaces across different illuminants. This ability is referred to as color constancy and it is essential for the organism to use color as a cue in object search, recognition, and identification. We devised images
of two surfaces presented under three different illuminants using physically realistic rendering methods to study the neural architecture underlying surface color perception. Measuring patterns of fMRI voxel activity elicited by these images, we tested to what extent responses to surface
color in various retinotopically mapped areas remained stable across illuminants and which regions encoded illuminant information. We made three important observations: First, patterns of fMRI responses to surface
color generalized across illuminants in V1 but not V2, V3, hV4, or VO1. Second, accuracy of illuminant decoding was positively correlated with psychophysically measured color constancy as predicted by the Equivalent Illuminant Model. Third, when fMRI activity was elicited by stimuli that
were matched in reflected light but differed in illumination and therefore also differed in perceived surface color, there was a gradient from lower to higher visual areas to distinguish between the two inputs in terms of a difference in surface color rather than illumination. Our results demonstrate that V1 represents chromatic invariances in the stimulus environment (possibly via feedback) whereas downstream visual areas are more
biased to link chromatic differences to different surface color percepts.},
   department = {Department Logothetis},
   web_url = {http://jov.arvojournals.org/article.aspx?articleid=2551130},
   event_place = {St. Pete Beach, FL, USA},
   event_name = {16th Annual Meeting of the Vision Sciences Society (VSS 2016)},
   DOI = {10.1167/16.12.1155},
   author = {Bannert, M and Bartels, A}
}

@Poster { BannertB2015,
   title = {The invariance of surface color representations across illuminant changes in the human cortex},
   year = {2015},
   month = {11},
   day = {5},
   pages = {67},
   abstract = {The light reflected from a surface depends on the reflectance of that surface and the spectral power distribution of the incident light, thus making it impossible to predict surface color directly from its wavelength composition. Despite this computational problem, the human visual system is remarkably accurate at inferring the color of surfaces across different illuminants. This ability is referred to as color constancy and it is essential for the organism to use color as a cue in object search, recognition, and identification. We devised images of two surfaces presented under three different illuminants using physically realistic rendering methods to disentangle the influences of wavelength composition, surface reflectance, and illumination. Measuring patterns of fMRI voxel activity elicited by these images we tested to what extent responses to surface color in various retinotopically mapped visual areas remained stable across illuminants. While surface color could be decoded in all ROIs when the illuminants did not differ between training and test sets, we found generalization across illuminants in V1 only. When viewing the scene in a cue conflict condition that abolished color constancy as measured psychophysically, generalization also broke down in V1. When fMRI activity was elicited by stimuli that were matched in reflected light but differed in illumination and therefore also perceived surface color, higher visual areas showed an increasing bias towards surface color representation and a decrease in illuminant color representation. Our results demonstrate the differential roles that V1 and V4 areas play in transforming chromatic input into color constant percepts.},
   department = {Department Logothetis},
   web_url = {http://www.ru.nl/dondersdiscussions/previous-events/dd2015/programme2015/},
   event_place = {Nijmegen, The Netherlands},
   event_name = {Donders Discussions 2015},
   author = {Bannert, MM and Bartels, A}
}

@Poster { BannertB2012,
   title = {Predicting memory color from neural responses to achromatic images of color-diagnostic objects},
   year = {2012},
   month = {10},
   day = {14},
   volume = {42},
   number = {261.10},
   abstract = {Some objects that we deal with on a daily basis are associated with an object-specific color [[unable to display character: \&\#8211;]] such as yellow for bananas, red for strawberries, green for lettuce, etc. Such objects are referred to as color-diagnostic and their associated color as their memory color (Hering, 1920). Psychophysical evidence shows that achromatic , i.e. grayscale, images of color-diagnostic objects elicit percepts that are differentially biased towards their memory color (Hansen, Olkkonen, Walter, \& Gegenfurtner, 2006; Olkkonen, Hansen, \& Gegenfurtner, 2008). This phenomenon suggests some form of learned and automatic association between colors and particular objects.
In the present study we tested whether neural responses to color-diagnostic objects convey color-specific information, even when the objects were presented achromatically to subjects who were na{\"i}ve to the purpose of the study.
We first collected fMRI data while participants viewed grayscale images of 8 different color-diagnostic objects (4 colors, 2 per color). We then recorded responses to chromatic stimulation with red, green, blue, and yellow abstract color stimuli that contained no object information. All object and color stimuli were set to equiluminance for each subject individually. To analyze the data, we applied a whole-brain searchlight procedure by training linear support vector machine classifiers to distinguish between local voxel patterns associated with the four colors. They were then tested on patterns elicited by color-diagnostic achromatic objects to predict their correct memory colors.
At the group level, we found significant decoding accuracy in a large cluster covering foveal regions of early visual cortex. In some but not all individual subjects, smaller clusters were also evident in the fusiform gyrus.
Our results suggest that memory color and color signals evoked by chromatic stimulation share a common neural mechanism in early visual cortex. Retinotopic mapping in combination with classification techniques will be used to clarify the contribution of individual visual areas to this mechanism.},
   department = {Department Logothetis},
   web_url = {http://www.abstractsonline.com/Plan/ViewAbstract.aspx?sKey=84193aad-2bac-4c16-b075-86ba04f67615\&cKey=70e8a431-7b35-4472-97f5-a1bcb918f1d4\&mKey=70007181-01c9-4de9-a0a2-eebfa14cd9f1},
   event_place = {New Orleans, LA, USA},
   event_name = {42nd Annual Meeting of the Society for Neuroscience (Neuroscience 2012)},
   author = {Bannert, MM and Bartels, A}
}

@Poster { BannertB2012_2,
   title = {The yellow of a gray banana: Decoding colors from fMRI
signals in the absence of chromatic stimulation},
   journal = {Frontiers in Computational Neuroscience},
   year = {2012},
   month = {9},
   day = {14},
   volume = {Conference Abstract: Bernstein Conference 2012},
   pages = {173},
   abstract = {Some objects that we deal with on a daily basis are associated with an object-specific color &ndash; such as yellow for bananas, red for strawberries, green for lettuce, etc. Such objects are referred to as color-diagnostic and their associated color as their memory color (Hering, 1920).
Psychophysical evidence shows that achromatic , i.e. grayscale, images of color-diagnostic objects elicit percepts that are differentially biased towards their memory color (Hansen et al., 2006; Olkkonen et al., 2008). This phenomenon suggests some form of learned and automatic
association between colors and particular objects. In the present study we tested whether neural responses to color-diagnostic objects convey color-specific information, even when the objects were presented achromatically to subjects
who were na{\"i}ve to the purpose of the study. We first collected fMRI data while participants viewed grayscale images of 8 different colordiagnostic objects (4 colors, 2 per color). We then recorded responses to chromatic stimulation with red, green, blue, and yellow abstract color stimuli that contained no object information.
All object and color stimuli were set to equiluminance for each subject individually. To analyze the data, we applied a whole-brain searchlight procedure by training linear support vector machine classifiers to distinguish between local voxel patterns associated with the four colors. They were then tested on patterns elicited by color-diagnostic achromatic objects to predict their correct memory colors.
At the group level, we found significant decoding accuracy in a large cluster covering foveal regions of early visual cortex. In some but not all individual subjects, smaller clusters were also evident in the fusiform gyrus. Our results suggest that memory color and color signals evoked by chromatic stimulation share a common neural mechanism in early visual cortex. Retinotopic mapping in combination
with classification techniques will be used to clarify the contribution of individual visual areas to this mechanism.},
   department = {Department Logothetis},
   web_url = {http://www.frontiersin.org/10.3389/conf.fncom.2012.55.00049/event_abstract?sname=Bernstein_Conference_2012},
   event_place = {M{\"u}nchen, Germany},
   event_name = {Bernstein Conference 2012},
   DOI = {10.3389/conf.fncom.2012.55.00049},
   author = {Bannert, MM and Bartels, A}
}

@Poster { FiehlerBFBSVR2011,
   title = {The anterior intraparietal sulcus contributes to visually-guided and memory-guided grasping},
   year = {2009},
   month = {10},
   volume = {39},
   number = {355.7},
   abstract = {There is general agreement about the posterior parietal cortex, in particular the anterior part of the intraparietal sulcus (aIPS), being engaged in visually guided grasping. The contribution of these areas to memory-guided grasping, however, is still controversial. Electrophysiological studies in monkeys suggest a role of the aIPS in both visually guided and memory-guided grasping. However, some results from patients suggest a dissociation such that the aIPS is involved in immediate grasping while the inferior temporal cortex is involved in memory-guided grasping. Using functional magnetic resonance imaging, we investigated the neural correlates of immediate and delayed grasping in healthy humans. Participants were asked to grasp three-dimensional objects of different size and orientation with their thumb and index finger of the dominant right hand (precision grip). Vision was controlled by liquid crystal shutter goggles that were opened during object presentation but closed during grasping, thus requiring open-loop grasping. An auditory signal either presented immediately after object presentation (immediate grasping) or after a variable delay of two to twelve seconds following object presentation (delayed grasping), signalled the start of the grasp movement. We analysed cortical activity during object presentation, maintenance of object information, and immediate and delayed grasping. Object presentation activated areas along the dorsal and ventral visual streams in both hemispheres and the left sensorimotor cortex. Short-term maintenance of action-related object information revealed activation in the right aIPS and adjacent inferior parietal cortex. A similar activation was observed for delayed in contrast to immediate grasping. In line with electrophysiological monkey data, our results indicate that the aIPS does not only contribute to visually-guided grasping but also stores action-related information used for subsequent memory-guided grasping.},
   web_url = {http://www.sfn.org/am2009/},
   event_place = {Chicago, IL, USA},
   event_name = {39th Annual Meeting of the Society for Neuroscience (Neuroscience 2009)},
   author = {Fiehler, K and Bannert, MM and Franz, VH and Bischoff, M and Stark, B and Vaitl, D and R{\"o}sler, F}
}

@Poster { DetrePBN2007,
   title = {Context in free recall: multi-voxel pattern analysis of fMRI},
   year = {2007},
   month = {11},
   volume = {37},
   number = {421.1},
   abstract = {Several researchers (e.g., Howard \& Kahana, 2002) have proposed that recalling an event is bound up with recall of that event's surrounding context, and that retrieved context information can be used to cue memory for other items from that context. In this study, we sought evidence for this contextual reinstatement process using fMRI. Specifically, we wanted to know whether the task being performed when forming a memory would be recalled along with that memory, and how this would influence subsequent recalls.
Subjects studied lists of 24 words, performing either a size, animacy or pleasantness judgment task on each word. After a series of arithmetic distractors, subjects were asked to recall out loud and in any order the words from the most recent list. Since subjects were being scanned during both study and recall phases, we trained a classifier on the study period to distinguish which of the three tasks were being performed. We then tested this classifier during recall to estimate the degree to which each task representation was active in the subject's mind, moment by moment (Polyn et al, 2005).
To analyze the recall data, we labelled each recall with its judgment task from the study period. These were predicted better than chance by the classifier's estimates of task activity at recall. We broke the data down further, looking at the transitions from one recall to the next. We found that high classifier activity for one kind of task judgment indicated that the next recall would be another item from that task, and that the inter-response latency would be small. In other words, a highly active task representation would facilitate recalls of other items from the same task.
These results support the contextual reinstatement theory, suggesting that reinstating the context surrounding an event improves recall of other items that were studied in that context.},
   url = {http://www.kyb.tuebingen.mpg.defileadmin/user_upload/files/publications/SFN07_detre.pdf},
   web_url = {http://www.sfn.org/am2007/},
   event_place = {San Diego, CA, USA},
   event_name = {37th Annual Meeting of the Society for Neuroscience (Neuroscience 2007)},
   author = {Detre, GJ and Polyn, SM and Bannert, MM and Norman, KA}
}

@Conference { BannertB2016_2,
   title = {The constructive nature of color vision: evidence from human fMRI},
   year = {2016},
   month = {9},
   day = {21},
   department = {Department Logothetis},
   talk_type = {Invited Lecture},
   web_url = {http://www.uni-regensburg.de/psychologie-paedagogik-sport/psychologie-greenlee/seeing-colors/index.html},
   event_place = {Regensburg, Germany},
   event_name = {Seeing Colors: International Symposium on Color Vision},
   author = {Bannert, MM and Bartels, A}
}

@Conference { BannertFBBSVRF2009,
   title = {Gibt es ein Kurzzeitged{\"a}chtnis f{\"u}r Greifbewegungen im parietalen Cortex?},
   year = {2009},
   month = {4},
   volume = {51},
   pages = {52},
   abstract = {Visuelle Kontrolle von Greifbewegungen erfordert die Anpassung der greifenden Hand an das Zielobjekt auf der Grundlage visueller Information {\"u}ber dessen physikalische Eigenschaften. Einzelzellableitungen an Affen zeigen, dass der anteriore intraparietale Sulcus auf die visuelle Kontrolle und kurzzeitige Speicherung von Greifbewegungen spezialisiert ist. Funktionelle Bildgebungsstudien deuten darauf hin, dass eine vergleichbare Region auch im menschlichen Gehirn existiert. Welche Rolle dieses Areal jedoch bei der kurzfristigen Speicherung visuomotorischer Repr{\"a}sentationen spielt, wird allerdings kontrovers diskutiert. In der aktuellen fMRT-Studie wurden Versuchspersonen instruiert, nach einem Behaltensintervall variabler Dauer blind nach einem zuvor visuell enkodierten Objekt zu greifen. In einer Kontrollbedingung griffen Versuchspersonen unmittelbar im Anschluss an die Enkodierungsphase nach dem Objekt. Wir finden eine anhaltende Aktivierung des anterioren intraparietalen Sulcus w{\"a}hrend des Behaltensintervalls. Dies steht im Einklang zu Befunden aus Einzelzellableitungen und aktuellen Arbeitsged{\"a}chtnistheorien, denen zufolge Regionen, die f{\"u}r die Echtzeitverarbeitung von Informationen zust{\"a}ndig sind, auch zu deren kurzzeitiger Speicherung beitragen.},
   talk_type = {Abstract Talk},
   web_url = {https://www.teap.de/memory/Tagungsband_TeaP_2009_Jena.pdf},
   event_place = {Jena, Germany},
   event_name = {51. Tagung Experimentell Arbeitender Psychologen (TeaP 2009)},
   author = {Bannert, MM and Franz, VH and Bischoff, M and Blecker, C and Stark, R and Vaitl, D and R{\"o}sler, F and Fiehler, K}
}

